{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import nan\n",
    "from future.utils import iteritems\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from utils import get_data, generate_output, guess_human, seed_sequence, get_embeddings, find_closest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import keras as k\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>Muslim</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>Brotherhood</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>parts</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence #           Word  POS    Tag\n",
       "0     Sentence: 1      Thousands  NNS      O\n",
       "1     Sentence: 1             of   IN      O\n",
       "2     Sentence: 1  demonstrators  NNS      O\n",
       "3     Sentence: 1           have  VBP      O\n",
       "4     Sentence: 1        marched  VBN      O\n",
       "..            ...            ...  ...    ...\n",
       "667  Sentence: 29         Muslim  NNP  B-org\n",
       "668  Sentence: 29    Brotherhood  NNP  I-org\n",
       "669  Sentence: 29             as   IN      O\n",
       "670  Sentence: 29          parts  NNS      O\n",
       "671  Sentence: 29             of   IN      O\n",
       "\n",
       "[672 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding= 'latin1') \n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35179 17\n"
     ]
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "nrofWords = len(words)\n",
    "\n",
    "ner_tags = list(set(data[\"Tag\"].values))\n",
    "nrofTags = len(tags)\n",
    "print(nrofWords, nrofTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                        s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "          \n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {w: i +1 for i, w in enumerate(words)}\n",
    "tag_index = {t: i for i, t in enumerate(ner_tags)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag_index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30055"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"universe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "word_embedding_size = 17\n",
    "\n",
    "X = [[word_index[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\",value=nrofWords - 1)\n",
    "\n",
    "y = [[tag_index[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=tag_index[\"O\"])\n",
    "y = [to_categorical(i, num_classes=nrofTags) for i in y]\n",
    "\n",
    "# Split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen,))\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=nrofWords+1, output_dim=20, input_length=maxlen),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(8, return_sequences=True)),\n",
    "    tf.keras.layers.Dense(nrofTags, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 104, 20)           703600    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 104, 16)           464       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 104, 17)           289       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 104, 17)           0         \n",
      "=================================================================\n",
      "Total params: 704,353\n",
      "Trainable params: 704,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1080/1080 [==============================] - 44s 41ms/step - loss: 0.5605 - accuracy: 0.2021 - val_loss: 0.3713 - val_accuracy: 0.9683\n",
      "Epoch 2/10\n",
      "1080/1080 [==============================] - 39s 37ms/step - loss: 0.4262 - accuracy: 0.4920 - val_loss: 0.3296 - val_accuracy: 0.9683\n",
      "Epoch 3/10\n",
      "1080/1080 [==============================] - 40s 37ms/step - loss: 0.4174 - accuracy: 0.4930 - val_loss: 0.3224 - val_accuracy: 0.9683\n",
      "Epoch 4/10\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 0.4155 - accuracy: 0.4921 - val_loss: 0.3198 - val_accuracy: 0.9683\n",
      "Epoch 5/10\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.4147 - accuracy: 0.4925 - val_loss: 0.3185 - val_accuracy: 0.9683\n",
      "Epoch 6/10\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.4143 - accuracy: 0.4925 - val_loss: 0.3179 - val_accuracy: 0.9683\n",
      "Epoch 7/10\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.4140 - accuracy: 0.4921 - val_loss: 0.3175 - val_accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "1080/1080 [==============================] - 40s 37ms/step - loss: 0.4135 - accuracy: 0.4919 - val_loss: 0.3169 - val_accuracy: 0.9691\n",
      "Epoch 9/10\n",
      "1080/1080 [==============================] - 40s 37ms/step - loss: 0.4127 - accuracy: 0.4921 - val_loss: 0.3163 - val_accuracy: 0.9706\n",
      "Epoch 10/10\n",
      "1080/1080 [==============================] - 44s 41ms/step - loss: 0.4125 - accuracy: 0.4920 - val_loss: 0.3160 - val_accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.summary()\n",
    "\n",
    "history_1 = model_1.fit(X_train, np.array(y_train), batch_size=32, epochs=10,\n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred_1 = model_1.predict(X_test, verbose=1)\n",
    "\n",
    "idx2tag = {i: w for w, i in tag_index.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred_1)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 24.8%\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      per       0.00      0.00      0.00      3376\n",
      "      org       0.01      0.00      0.00      4046\n",
      "      gpe       0.00      0.00      0.00      3059\n",
      "      geo       0.36      0.32      0.34      7538\n",
      "      tim       0.28      0.52      0.36      4066\n",
      "      eve       0.00      0.00      0.00        69\n",
      "      nat       0.00      0.00      0.00        42\n",
      "      art       0.00      0.00      0.00        65\n",
      "\n",
      "micro avg       0.31      0.21      0.25     22261\n",
      "macro avg       0.18      0.21      0.18     22261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "Qantas         : B-org O\n",
      "chief          : O     O\n",
      "executive      : O     O\n",
      "Alan           : B-per O\n",
      "Joyce          : I-per O\n",
      "joined         : O     O\n",
      "the            : O     O\n",
      "first          : O     O\n",
      "leg            : O     O\n",
      "of             : O     O\n",
      "the            : O     O\n",
      "flight         : O     O\n",
      "to             : O     O\n",
      "London         : B-geo B-geo\n",
      "via            : O     O\n",
      "Singapore      : B-geo O\n",
      ".              : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 1928\n",
    "p = model_1.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_test[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-1], ner_tags[t], ner_tags[pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=nrofWords+1, output_dim=word_embedding_size, input_length=maxlen),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Dense(nrofTags, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 104, 17)           598060    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 104, 128)          41984     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 104, 17)           2193      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 104, 17)           0         \n",
      "=================================================================\n",
      "Total params: 642,237\n",
      "Trainable params: 642,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 0.4553 - accuracy: 0.4892 - val_loss: 0.3191 - val_accuracy: 0.9679\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 0.4143 - accuracy: 0.4922 - val_loss: 0.3178 - val_accuracy: 0.9679\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 48s 81ms/step - loss: 0.4140 - accuracy: 0.4919 - val_loss: 0.3175 - val_accuracy: 0.9679\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 0.4139 - accuracy: 0.4920 - val_loss: 0.3174 - val_accuracy: 0.9679\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 47s 78ms/step - loss: 0.4138 - accuracy: 0.4917 - val_loss: 0.3173 - val_accuracy: 0.9679\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 47s 78ms/step - loss: 0.4138 - accuracy: 0.4919 - val_loss: 0.3173 - val_accuracy: 0.9679\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 47s 79ms/step - loss: 0.4138 - accuracy: 0.4919 - val_loss: 0.3172 - val_accuracy: 0.9679\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 47s 78ms/step - loss: 0.4138 - accuracy: 0.4917 - val_loss: 0.3171 - val_accuracy: 0.9679\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 47s 78ms/step - loss: 0.4136 - accuracy: 0.4919 - val_loss: 0.3170 - val_accuracy: 0.9679\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 47s 78ms/step - loss: 0.4132 - accuracy: 0.4915 - val_loss: 0.3164 - val_accuracy: 0.9679\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 47s 79ms/step - loss: 0.4127 - accuracy: 0.4917 - val_loss: 0.3160 - val_accuracy: 0.9679\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 0.4124 - accuracy: 0.4917 - val_loss: 0.3158 - val_accuracy: 0.9679\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 48s 79ms/step - loss: 0.4125 - accuracy: 0.4919 - val_loss: 0.3157 - val_accuracy: 0.9678\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 47s 79ms/step - loss: 0.4124 - accuracy: 0.4914 - val_loss: 0.3157 - val_accuracy: 0.9678\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 47s 79ms/step - loss: 0.4122 - accuracy: 0.4915 - val_loss: 0.3156 - val_accuracy: 0.9679\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 0.4122 - accuracy: 0.4924 - val_loss: 0.3156 - val_accuracy: 0.9679\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 48s 79ms/step - loss: 0.4121 - accuracy: 0.4912 - val_loss: 0.3155 - val_accuracy: 0.9682\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 0.4122 - accuracy: 0.4921 - val_loss: 0.3155 - val_accuracy: 0.9685\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 49s 81ms/step - loss: 0.4123 - accuracy: 0.4916 - val_loss: 0.3155 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 0.4122 - accuracy: 0.4921 - val_loss: 0.3155 - val_accuracy: 0.9692\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 50s 83ms/step - loss: 0.4121 - accuracy: 0.4916 - val_loss: 0.3155 - val_accuracy: 0.9693\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 0.4121 - accuracy: 0.4921 - val_loss: 0.3155 - val_accuracy: 0.9695\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 63s 105ms/step - loss: 0.4120 - accuracy: 0.4922 - val_loss: 0.3154 - val_accuracy: 0.9698\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 51s 84ms/step - loss: 0.4121 - accuracy: 0.4922 - val_loss: 0.3154 - val_accuracy: 0.9699\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 49s 82ms/step - loss: 0.4121 - accuracy: 0.4925 - val_loss: 0.3154 - val_accuracy: 0.9699\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 0.4120 - accuracy: 0.4930 - val_loss: 0.3154 - val_accuracy: 0.9720\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 50s 84ms/step - loss: 0.4120 - accuracy: 0.4930 - val_loss: 0.3153 - val_accuracy: 0.9723\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 49s 82ms/step - loss: 0.4119 - accuracy: 0.4938 - val_loss: 0.3153 - val_accuracy: 0.9725\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 49s 82ms/step - loss: 0.4119 - accuracy: 0.4941 - val_loss: 0.3153 - val_accuracy: 0.9726\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 0.4119 - accuracy: 0.4944 - val_loss: 0.3153 - val_accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train, np.array(y_train), batch_size=32, epochs=30,\n",
    "                    validation_split=0.5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred_2 = model_2.predict(X_test, verbose=1)\n",
    "\n",
    "#idx2tag = {i: w for w, i in index_tag.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred_2)\n",
    "test_labels = pred2label(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 11.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      per       0.14      0.61      0.22      3376\n",
      "      org       0.00      0.00      0.00      4046\n",
      "      gpe       0.00      0.00      0.00      3059\n",
      "      geo       0.00      0.00      0.00      7538\n",
      "      tim       0.00      0.00      0.00      4066\n",
      "      eve       0.00      0.00      0.00        69\n",
      "      nat       0.00      0.00      0.00        42\n",
      "      art       0.00      0.00      0.00        65\n",
      "\n",
      "micro avg       0.14      0.09      0.11     22261\n",
      "macro avg       0.02      0.09      0.03     22261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "In             : O     O\n",
      "it             : O     O\n",
      ",              : O     O\n",
      "Zawahiri       : B-per O\n",
      "appeared       : O     O\n",
      "in             : O     O\n",
      "front          : O     O\n",
      "of             : O     O\n",
      "a              : O     O\n",
      "portrait       : O     O\n",
      "of             : O     O\n",
      "Zarqawi        : B-geo B-geo\n",
      ".              : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n",
      "physicist      : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 2007\n",
    "p = model_1.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_test[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-1], ner_tags[t], ner_tags[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
