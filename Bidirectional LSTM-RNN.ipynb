{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import nan\n",
    "from future.utils import iteritems\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from utils import get_data, generate_output, guess_human, seed_sequence, get_embeddings, find_closest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import keras as k\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>Muslim</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>Brotherhood</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>parts</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Sentence: 29</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence #           Word  POS    Tag\n",
       "0     Sentence: 1      Thousands  NNS      O\n",
       "1     Sentence: 1             of   IN      O\n",
       "2     Sentence: 1  demonstrators  NNS      O\n",
       "3     Sentence: 1           have  VBP      O\n",
       "4     Sentence: 1        marched  VBN      O\n",
       "..            ...            ...  ...    ...\n",
       "667  Sentence: 29         Muslim  NNP  B-org\n",
       "668  Sentence: 29    Brotherhood  NNP  I-org\n",
       "669  Sentence: 29             as   IN      O\n",
       "670  Sentence: 29          parts  NNS      O\n",
       "671  Sentence: 29             of   IN      O\n",
       "\n",
       "[672 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_dataset.csv\", encoding= 'latin1') \n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35179 17\n",
      "['B-org', 'B-gpe', 'O', 'I-geo', 'B-per', 'I-art', 'I-org', 'B-tim', 'I-per', 'I-tim', 'I-eve', 'I-nat', 'B-art', 'I-gpe', 'B-eve', 'B-nat', 'B-geo']\n"
     ]
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "nrofWords = len(words)\n",
    "\n",
    "ner_tags = list(set(data[\"Tag\"].values))\n",
    "nrofTags = len(ner_tags)\n",
    "print(nrofWords, nrofTags)\n",
    "print(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                        s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "          \n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {w: i +1 for i, w in enumerate(words)}\n",
    "tag_index = {t: i for i, t in enumerate(ner_tags)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag_index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"universe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "word_embedding_size = 17\n",
    "\n",
    "X = [[word_index[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\",value=nrofWords - 1)\n",
    "\n",
    "y = [[tag_index[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=tag_index[\"O\"])\n",
    "y = [to_categorical(i, num_classes=nrofTags) for i in y]\n",
    "\n",
    "# Split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen,))\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=nrofWords+1, output_dim=20, input_length=maxlen),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(32, return_sequences=True)),\n",
    "    tf.keras.layers.Dense(nrofTags, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 104, 20)           703600    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 104, 128)          10880     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 104, 17)           2193      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 104, 17)           0         \n",
      "=================================================================\n",
      "Total params: 716,673\n",
      "Trainable params: 716,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "960/960 [==============================] - 49s 51ms/step - loss: 0.4316 - accuracy: 0.5957 - val_loss: 0.3189 - val_accuracy: 0.9680\n",
      "Epoch 2/30\n",
      "960/960 [==============================] - 41s 42ms/step - loss: 0.4142 - accuracy: 0.6065 - val_loss: 0.3176 - val_accuracy: 0.9680\n",
      "Epoch 3/30\n",
      "960/960 [==============================] - 40s 41ms/step - loss: 0.4140 - accuracy: 0.6059 - val_loss: 0.3173 - val_accuracy: 0.9680\n",
      "Epoch 4/30\n",
      "960/960 [==============================] - 43s 44ms/step - loss: 0.4137 - accuracy: 0.6065 - val_loss: 0.3171 - val_accuracy: 0.9680\n",
      "Epoch 5/30\n",
      "960/960 [==============================] - 41s 43ms/step - loss: 0.4138 - accuracy: 0.6067 - val_loss: 0.3170 - val_accuracy: 0.9680\n",
      "Epoch 6/30\n",
      "960/960 [==============================] - 39s 41ms/step - loss: 0.4136 - accuracy: 0.6064 - val_loss: 0.3169 - val_accuracy: 0.9680\n",
      "Epoch 7/30\n",
      "960/960 [==============================] - 39s 41ms/step - loss: 0.4136 - accuracy: 0.6060 - val_loss: 0.3168 - val_accuracy: 0.9680\n",
      "Epoch 8/30\n",
      "960/960 [==============================] - 40s 42ms/step - loss: 0.4129 - accuracy: 0.6066 - val_loss: 0.3160 - val_accuracy: 0.9681\n",
      "Epoch 9/30\n",
      "960/960 [==============================] - 40s 42ms/step - loss: 0.4124 - accuracy: 0.6069 - val_loss: 0.3157 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "960/960 [==============================] - 40s 42ms/step - loss: 0.4123 - accuracy: 0.6074 - val_loss: 0.3156 - val_accuracy: 0.9690\n",
      "Epoch 11/30\n",
      "960/960 [==============================] - 40s 41ms/step - loss: 0.4122 - accuracy: 0.6067 - val_loss: 0.3155 - val_accuracy: 0.9698\n",
      "Epoch 12/30\n",
      "960/960 [==============================] - 40s 42ms/step - loss: 0.4121 - accuracy: 0.6074 - val_loss: 0.3155 - val_accuracy: 0.9698\n",
      "Epoch 13/30\n",
      "960/960 [==============================] - 47s 48ms/step - loss: 0.4121 - accuracy: 0.6073 - val_loss: 0.3154 - val_accuracy: 0.9700\n",
      "Epoch 14/30\n",
      "960/960 [==============================] - 43s 45ms/step - loss: 0.4121 - accuracy: 0.6080 - val_loss: 0.3154 - val_accuracy: 0.9723\n",
      "Epoch 15/30\n",
      "960/960 [==============================] - 41s 43ms/step - loss: 0.4119 - accuracy: 0.6088 - val_loss: 0.3153 - val_accuracy: 0.9726\n",
      "Epoch 16/30\n",
      "960/960 [==============================] - 41s 43ms/step - loss: 0.4119 - accuracy: 0.6090 - val_loss: 0.3153 - val_accuracy: 0.9727\n",
      "Epoch 17/30\n",
      "960/960 [==============================] - 42s 43ms/step - loss: 0.4119 - accuracy: 0.6094 - val_loss: 0.3152 - val_accuracy: 0.9729\n",
      "Epoch 18/30\n",
      "960/960 [==============================] - 42s 44ms/step - loss: 0.4118 - accuracy: 0.6099 - val_loss: 0.3152 - val_accuracy: 0.9730\n",
      "Epoch 19/30\n",
      "960/960 [==============================] - 44s 45ms/step - loss: 0.4118 - accuracy: 0.6100 - val_loss: 0.3152 - val_accuracy: 0.9730\n",
      "Epoch 20/30\n",
      "960/960 [==============================] - 41s 43ms/step - loss: 0.4118 - accuracy: 0.6101 - val_loss: 0.3152 - val_accuracy: 0.9731\n",
      "Epoch 21/30\n",
      "960/960 [==============================] - 39s 41ms/step - loss: 0.4118 - accuracy: 0.6103 - val_loss: 0.3152 - val_accuracy: 0.9732\n",
      "Epoch 22/30\n",
      "960/960 [==============================] - 37s 38ms/step - loss: 0.4118 - accuracy: 0.6099 - val_loss: 0.3152 - val_accuracy: 0.9732\n",
      "Epoch 23/30\n",
      "960/960 [==============================] - 38s 40ms/step - loss: 0.4118 - accuracy: 0.6097 - val_loss: 0.3152 - val_accuracy: 0.9732\n",
      "Epoch 24/30\n",
      "960/960 [==============================] - 42s 44ms/step - loss: 0.4118 - accuracy: 0.6100 - val_loss: 0.3152 - val_accuracy: 0.9733\n",
      "Epoch 25/30\n",
      "960/960 [==============================] - 38s 40ms/step - loss: 0.4117 - accuracy: 0.6104 - val_loss: 0.3152 - val_accuracy: 0.9733\n",
      "Epoch 26/30\n",
      "960/960 [==============================] - 43s 45ms/step - loss: 0.4118 - accuracy: 0.6106 - val_loss: 0.3152 - val_accuracy: 0.9734\n",
      "Epoch 27/30\n",
      "960/960 [==============================] - 44s 46ms/step - loss: 0.4117 - accuracy: 0.6104 - val_loss: 0.3152 - val_accuracy: 0.9734\n",
      "Epoch 28/30\n",
      "960/960 [==============================] - 41s 43ms/step - loss: 0.4118 - accuracy: 0.6100 - val_loss: 0.3151 - val_accuracy: 0.9734\n",
      "Epoch 29/30\n",
      "960/960 [==============================] - 39s 41ms/step - loss: 0.4118 - accuracy: 0.6105 - val_loss: 0.3151 - val_accuracy: 0.9734\n",
      "Epoch 30/30\n",
      "960/960 [==============================] - 39s 41ms/step - loss: 0.4117 - accuracy: 0.6107 - val_loss: 0.3151 - val_accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.summary()\n",
    "\n",
    "history_1 = model_1.fit(X_train, np.array(y_train), batch_size=32, epochs=10,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred_1 = model_1.predict(X_test, verbose=1)\n",
    "\n",
    "idx2tag = {i: w for w, i in tag_index.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred_1)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 13.1%\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      org       0.00      0.00      0.00      4087\n",
      "      gpe       0.00      0.00      0.00      3190\n",
      "      geo       0.00      0.00      0.00      7434\n",
      "      tim       0.00      0.00      0.00      4133\n",
      "      per       0.15      0.77      0.25      3364\n",
      "      art       0.00      0.00      0.00        84\n",
      "      eve       0.00      0.00      0.00        60\n",
      "      nat       0.00      0.00      0.00        46\n",
      "\n",
      "micro avg       0.15      0.12      0.13     22398\n",
      "macro avg       0.02      0.12      0.04     22398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "The            : O     O\n",
      "Bloomberg      : B-org B-per\n",
      "financial      : O     O\n",
      "news           : O     O\n",
      "service        : O     O\n",
      "reports        : O     O\n",
      "Kenya          : B-geo B-per\n",
      "received       : O     O\n",
      "more           : O     O\n",
      "than           : O     O\n",
      "one            : O     O\n",
      "million        : O     O\n",
      "tourists       : O     O\n",
      "in             : O     O\n",
      "the            : O     O\n",
      "first          : B-tim O\n",
      "nine           : I-tim O\n",
      "months         : O     O\n",
      "of             : B-tim O\n",
      "2007           : I-tim I-per\n",
      "and            : O     O\n",
      "is             : O     O\n",
      "the            : O     O\n",
      "largest        : O     O\n",
      "exporter       : O     O\n",
      "of             : O     O\n",
      "black          : O     O\n",
      "tea            : O     O\n",
      "in             : O     O\n",
      "the            : O     O\n",
      "world          : O     O\n",
      ".              : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n",
      "Raising        : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 1928\n",
    "p = model_1.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_test[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-1], ner_tags[t], ner_tags[pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=nrofWords+1, output_dim=word_embedding_size, input_length=maxlen),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Dense(nrofTags, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 104, 17)           598060    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 104, 128)          41984     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 104, 17)           2193      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 104, 17)           0         \n",
      "=================================================================\n",
      "Total params: 642,237\n",
      "Trainable params: 642,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 89s 148ms/step - loss: 0.4138 - accuracy: 0.6061 - val_loss: 0.3173 - val_accuracy: 0.9678\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 78s 130ms/step - loss: 0.4138 - accuracy: 0.6057 - val_loss: 0.3173 - val_accuracy: 0.9678\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 75s 126ms/step - loss: 0.4137 - accuracy: 0.6066 - val_loss: 0.3172 - val_accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 84s 140ms/step - loss: 0.4137 - accuracy: 0.6056 - val_loss: 0.3171 - val_accuracy: 0.9678\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 79s 131ms/step - loss: 0.4136 - accuracy: 0.6065 - val_loss: 0.3171 - val_accuracy: 0.9678\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train, np.array(y_train), batch_size=32, epochs=5,\n",
    "                    validation_split=0.5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred_2 = model_2.predict(X_test, verbose=1)\n",
    "\n",
    "#idx2tag = {i: w for w, i in index_tag.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred_2)\n",
    "test_labels = pred2label(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      org       0.00      0.00      0.00      4087\n",
      "      gpe       0.00      0.00      0.00      3190\n",
      "      geo       0.00      0.00      0.00      7434\n",
      "      tim       0.00      0.00      0.00      4133\n",
      "      per       0.00      0.00      0.00      3364\n",
      "      art       0.00      0.00      0.00        84\n",
      "      eve       0.00      0.00      0.00        60\n",
      "      nat       0.00      0.00      0.00        46\n",
      "\n",
      "micro avg       0.00      0.00      0.00     22398\n",
      "macro avg       0.00      0.00      0.00     22398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2007\n",
    "p = model_1.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_test[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-1], ner_tags[t], ner_tags[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
